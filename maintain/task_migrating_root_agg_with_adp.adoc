---
permalink: maintain/task_migrating_root_agg_with_adp.html 
sidebar: sidebar 
keywords: metrocluster, maintain, service, migrate, root, aggregate, adp, disks, partition, advanced, disk, partitioning 
summary: 'ADP(고급 디스크 파티셔닝)를 사용하는 기존 루트 애그리게이트를 중단 없이 마이그레이션할 수 있습니다.' 
---
= MetroCluster IP 구성에서 ADP로 구성된 루트 애그리게이트를 마이그레이션합니다
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


루트 애그리게이트에 공간이 부족하거나 대용량 SSD를 사용하여 전환하려는 경우 ADP(고급 디스크 파티셔닝)를 사용하는 기존 루트 애그리게이트를 중단 없이 마이그레이션할 수 있습니다.

.이 작업에 대해
* 스토리지 페일오버를 위해서는 로컬 HA(고가용성) 쌍이 활성화되어 있어야 합니다.
* 이 절차는 무중단으로 수행할 수 있으며
* 이 구성은 빈번한 중단 없이 정상 작동 상태로 데이터를 제공하고 있어야 합니다.
* 이 절차를 수행하는 동안 운영 중단을 일으킬 수 있는 하드웨어 업그레이드나 기타 작업을 수행하지 마십시오.
* 한 번에 하나의 루트 애그리게이트만 마이그레이션할 수 있습니다. 두 루트 애그리게이트를 동시에 마이그레이션하려고 하지 마십시오.


.단계
. [[STEP_1, 구성 상태 확인]] 구성 상태를 확인합니다.
+
.. 각 클러스터에서 MetroCluster가 정상 모드로 구성되어 있는지 확인합니다.
 를 누릅니다
`metrocluster show`
+
[listing]
----
cluster_A::> metrocluster show
Cluster                   Entry Name          State
------------------------- ------------------- -----------
 Local: cluster_A         Configuration state configured
                          Mode                normal
                          AUSO Failure Domain auso-on-cluster-disaster
Remote: cluster_B         Configuration state configured
                          Mode                normal
                          AUSO Failure Domain auso-on-cluster-disaster
----
.. 각 노드에서 미러링이 활성화되어 있는지 확인합니다.
+
'MetroCluster node show'

+
[listing]
----
cluster_A::> metrocluster node show
DR                           Configuration  DR
Group Cluster Node           State          Mirroring Mode
----- ------- -------------- -------------- --------- --------
1     cluster_A
              node_A_1       configured     enabled   normal
      cluster_B
              node_B_1       configured     enabled   normal
2 entries were displayed.
----
.. MetroCluster 구성 요소가 정상인지 점검한다.
+
'MetroCluster check run

+
[listing]
----
cluster_A::> metrocluster check run

Last Checked On: 10/1/2014 16:03:37

Component           Result
------------------- ---------
nodes               ok
lifs                ok
config-replication  ok
aggregates          ok
4 entries were displayed.

Command completed. Use the "metrocluster check show -instance" command or sub-commands in "metrocluster check" directory for detailed results.
To check if the nodes are ready to do a switchover or switchback operation, run "metrocluster switchover -simulate" or "metrocluster switchback -simulate", respectively.
----
.. 상태 경고가 없는지 확인합니다.
+
'시스템 상태 경고 표시



. 스토리지 페일오버에 로컬 HA 쌍이 설정되었는지 확인합니다.
+
'스토리지 페일오버 쇼'

+
결과는 양쪽 노드에서 테이크오버 가능 여부를 표시해야 합니다.

+
[listing]
----
cluster_A::> storage failover show
                              Takeover
Node           Partner        Possible State Description
-------------- -------------- -------- ---------------------------
cluster-01     cluster-02      true     Connected to cluster-02

cluster-02     cluster-01      true     Connected to cluster-01
2 entries were displayed.
----
. 스페어 디스크를 제로화:
+
`run * disk zero spares`

. 루트 애그리게이트 크기 식별:
+
`node run local aggr status -r <root_agg_name>`

+
다음 예제에서 루트 애그리게이트에는 "pool0"에 10개의 디스크가 있고 "Pool1"에 10개의 디스크가 있습니다.

+
[listing]
----
cluster_A::*> node run local aggr status -r <root_agg_name>
Aggregate <root_agg_name> (online, raid_dp, mirrored, fast zeroed) (block checksums)
  Plex /<root_agg_name>/plex0 (online, normal, active, pool0)
    RAID group /<root_agg_name>/plex0/rg0 (normal, block checksums, max_wdbn 5767167)

      RAID Disk Device  HA  SHELF BAY CHAN Pool Type  RPM  Used (MB/blks)    Phys (MB/blks)
      --------- ------  ------------- ---- ---- ---- ----- --------------    --------------
      dparity   e2a.11.0.0P3    e2a   11  0   NV:A   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      parity    e10b.11.3.1P3   e10b  11  1   NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e2a.11.0.2P3    e2a   11  2   NV:A   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e2a.11.0.3P3    e2a   11  3   NV:A   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e2a.11.0.4P3    e2a   11  4   NV:A   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.5P3   e10b  11  5   NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.12P3  e10b  11  12  NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.13P3  e10b  11  13  NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.14P3  e10b  11  14  NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.15P3  e10b  11  15  NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)

  Plex /<root_agg_name>/plex2 (online, normal, active, pool1)
    RAID group /<root_agg_name>/plex2/rg0 (normal, block checksums, max_wdbn 5767167)

      RAID Disk Device  HA  SHELF BAY CHAN Pool Type  RPM  Used (MB/blks)    Phys (MB/blks)
      --------- ------  ------------- ---- ---- ---- ----- --------------    --------------
      dparity   0m.i2.2L1P3     0m    22  5          1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      parity    0m.i1.0L36P3    0m    22  14         1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0v.i2.2L18P3    0v    22  12         1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0v.i2.3L17P3    0v    22  2          1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0v.i1.0L25P3    0v    22  13         1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0v.i1.0L40P3    0v    22  4          1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0m.i1.1L39P3    0m    22  17         1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0m.i1.1L46P3    0m    22  15         1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0m.i2.3L13P3    0m    22  0          1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      0v.i1.1L26P3    0v    22  1          1 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)

cluster_A::*>
----
. 컨테이너 디스크를 할당합니다.
+
디스크를 할당하기 전에 각 노드에 권장되는 스페어 드라이브 수가 할당되었는지 확인합니다. 이러한 드라이브는 루트 애그리게이트가 마이그레이션되기 전에 파티셔닝됩니다. 자세한 내용은 을 참조하십시오 link:https://docs.netapp.com/us-en/ontap-metrocluster/install-ip/concept_considerations_drive_assignment.html["ONTAP 9.4 이상의 자동 드라이브 할당 및 ADP 시스템에 대한 고려 사항"].

+
다음 명령을 실행하여 디스크를 할당합니다.

+
`storage disk assign -disklist 1.11.0,1.11.1,…  -owner cluster-01 -pool 0`

. 루트 파티션 크기를 확인합니다.
+
루트 파티션 크기는 각 노드의 파티션에 사용할 수 있는 디스크 수에 따라 달라집니다. NetApp에서는 파티션에 대해 노드당 12개 이상의 드라이브를 사용할 것을 권장합니다.

+
다음 표를 사용하여 루트 애그리게이트 레이아웃을 확인할 수 있습니다.

+
[cols="25,75"]
|===
| 분할할 디스크 수입니다 | 루트 애그리게이트 레이아웃 


| 노드당 디스크 4개 | 데이터 드라이브 2개 및 패리티 드라이브 2개 


| 노드당 디스크 12개 | 데이터 드라이브 8개, 패리티 드라이브 2개 및 스페어 드라이브 2개 


| 노드당 디스크 24개 | 데이터 드라이브 20개, 패리티 드라이브 2개 및 스페어 드라이브 2개 
|===
+
루트 파티션 크기를 확인하려면 모든 데이터 드라이브 간에 총 4K 블록 수를 균등하게 나눕니다.

+
예를 들어 8개의 데이터 드라이브, 2개의 패리티 드라이브 및 1개의 루트 애그리게이트 크기가 112958795 블록인 2개의 스페어 드라이브로 구성된 루트 애그리게이트 레이아웃이 있는 경우 112958795를 8로 나누어야 루트 파티션 크기를 얻을 수 있습니다.

+
(112958795/8) = 14119849.375

+
이 그림을 반올림하면 루트 파티션 크기는 14119850입니다.

. 루트 애그리게이트에서 각 디스크를 파티셔닝합니다.
+
`cluster_A*> disk partition -n 3 -i 3 -b <root_partition_size> <disk_id>`

. 파티션을 할당합니다.
+

NOTE: ADP를 사용하는 시스템에서는 각 드라이브가 P1, P2, P3 파티션으로 분할되는 파티션을 사용하여 애그리게이트를 생성합니다.

+
.. 컨테이너 디스크를 소유하는 동일한 노드에 P3 파티션을 할당합니다.
+
`storage disk assign -disk <disk_id> -root true -pool 0 -owner cluster-01`

.. HA 쌍에서 더 낮은 시스템 ID 번호를 사용하여 시스템에 P1 파티션을 할당합니다.
+
`storage disk assign -disk <disk_id> -data1 true -pool 0 -owner cluster-01`

.. HA 쌍에서 상위 시스템 ID 번호가 있는 시스템에 P2 파티션을 할당합니다.
+
`storage disk assign -disk <disk_name> -data2 true -pool 0 -owner cluster-02`

+
분할된 모든 디스크에 대해 이 단계를 반복합니다.



. 테이크오버가 가능한지 확인:
+
'스토리지 페일오버 쇼'

+
[listing]
----
cluster_A::> storage failover show
                              Takeover
Node           Partner        Possible State Description
-------------- -------------- -------- ---------------------------
cluster-01     cluster-02      true     Connected to cluster-02

cluster-02     cluster-01      true     Connected to cluster-01
2 entries were displayed.
----
. 루트 애그리게이트를 마이그레이션합니다.
+
각 노드에 대해 pool0의 디스크 목록과 타겟 RAID 유형을 매개 변수로 지정하는 마이그레이션을 수행합니다.

+
`system node migrate-root -node cluster-01 -disklist <pool0_disk_list> -raid-type <target_raid_type>`

+
예를 들어, "cluster-01"의 루트 애그리게이트가 "RAID_DP"가 포함된 디스크 10개로 구성된 경우 다음 명령은 루트 애그리게이트를 마이그레이션합니다.

+
[listing]
----
system node migrate-root -node cluster-01 -disklist 1.11.1.P3,1.11.2.P3,1.11.3.P3,1.11.4.P3,1.11.5.P3,1.11.6.P3,1.11.7.P3,1.11.8.P3,1.11.9.P3,1.11.10.P3 -raid-type raid_dp

Warning: This is a partially automated and guided procedure for migrating the
         root aggregate on the node "cluster-01".
         Negotiated switchover is about to start.
         Warning: This operation will create a new root aggregate and replace
         the existing root on the node "cluster-01". The existing root
         aggregate will be discarded.
Do you want to continue? {y|n}: y

Info: Started migrate-root job. Run "job show -id 51 -instance" command to
      check the progress of the job.
      Once the job is complete, mirror the root aggregate using the "storage
      aggregate mirror" command
----
+

IMPORTANT: 디스크 수가 충분하지 않은 경우 디스크를 추가하거나 다른 RAID 유형을 선택하십시오.

+
마이그레이션 프로세스를 완료하는 데 몇 분 정도 걸릴 수 있습니다. 마이그레이션 중에 노드가 여러 번 재부팅되고 다른 노드에 오류가 표시될 수 있으므로 이 오류를 무시해도 마이그레이션 프로세스가 완료될 때까지 기다릴 수 있습니다.

. 필요한 경우 마이그레이션 진행률을 모니터링합니다.
+
두 번째 사이트에서 다음을 실행합니다.

+
`job show -id 51 -instance`

. 모든 MetroCluster IP 노드에 대해 RAID 자동 파티셔닝 다시 설정:
+
`storage raidlm policy modify -node <node> -policy-name auto_partition_ssds_post_init -policy-type Shared-Disk -is-enable true`

. 마이그레이션에 성공했는지 확인:
+
`run local aggr status -r <root_agg_name>`

+
[listing]
----
cluster_A::*> node run local aggr status -r <root_agg_name>
Aggregate <root_agg_name> (online, raid0, fast zeroed) (block checksums)
  Plex /<root_agg_name>/plex0 (online, normal, active, pool0)
    RAID group /<root_agg_name>/plex0/rg0 (normal, block checksums, max_wdbn 6127616)

      RAID Disk Device  HA  SHELF BAY CHAN Pool Type  RPM  Used (MB/blks)    Phys (MB/blks)
      --------- ------  ------------- ---- ---- ---- ----- --------------    --------------
      data      e2a.11.0.16P3   e2a   11  16  NV:A   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)
      data      e10b.11.3.17P3  e10b  11  17  NV:B   0 SSD-NVM   N/A 23956/6132864     23964/6134912 (fast zeroed)

cluster_A::*>
----
. ~ 단계를 반복합니다 <<step_1,구성 상태를 확인합니다>>.

